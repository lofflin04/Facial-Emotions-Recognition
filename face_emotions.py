# -*- coding: utf-8 -*-
"""face_emotions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wn7Yo1fACfKRzyHscl-2rb8aegck5GWk
"""

!git clone https://github.com/muxspace/facial_expressions.git

import csv
data = {}
with open("/content/facial_expressions/data/legend.csv") as f:
  reader = csv.reader(f)
  next(reader)
  for r in reader:
    key = r[2].lower()
    if key in data:
      data[key].append(r[1])
    else:
      data[key] = [r[1]]

list_emotions = list(data.keys())
list_emotions

import os
os.mkdir("master")
os.mkdir("master/train_data")
os.mkdir("master/test_data")

for emotion in list_emotions:
  os.mkdir(os.path.join("master/train_data/" , emotion))
  os.mkdir(os.path.join("master/test_data/" , emotion))

from shutil import copyfile

t_t_split = 0.8

#data has image name, emotion

for emotion, image_list in data.items():
  split_length = int(t_t_split * len(image_list))
  train_images = image_list[:split_length]
  test_images = image_list[split_length:]
  
  for image in train_images:
    source = os.path.join('/content/facial_expressions/images', image)
    dest = os.path.join('/content/master/train_data', emotion , image)
    copyfile(source, dest)
  for image in test_images:
    source = os.path.join('/content/facial_expressions/images', image)
    dest = os.path.join('/content/master/test_data', emotion , image)
    copyfile(source, dest)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/content/master/train_data'
test_dir = '/content/master/test_data'

train_datagen = ImageDataGenerator(rescale=1.0/ 255)
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (100,100),
    class_mode = 'categorical',
    batch_size = 128
)
test_datagen = ImageDataGenerator(rescale=1.0/ 255)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size = (100,100),
    class_mode = 'categorical',
    batch_size = 128
)

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,Flatten

model = tf.keras.models.Sequential([
                               Conv2D(16, (3, 3), activation = 'relu', input_shape = (100,100,3)),
                               MaxPooling2D(2,2),
                               Conv2D(32, (3, 3), activation = 'relu'),
                               MaxPooling2D(2,2),
                               Conv2D(64, (3, 3), activation = 'relu'),
                               MaxPooling2D(2,2),
                               Flatten(),
                               Dense(1024, activation = 'relu'),
                               Dense(8, activation = 'softmax')

]
)

model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])
model.summary()

es = EarlyStopping(monitor = 'val_acc', patience = 2, min_delta = 0.01)

model.fit_generator(
    train_generator,
    epochs = 10,
    verbose = 1,
    validation_data = test_generator,
    callbacks = [es]
)